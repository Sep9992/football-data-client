# ml/step3b_poisson_model.py
# Dixon-Coles Model (Poisson + Rho Correction)
# UPDATED: VÃ½poÄet parametru Rho pro korekci nÃ­zko skÃ³rujÃ­cÃ­ch remÃ­z

import os
import pandas as pd
import numpy as np
import joblib
from sqlalchemy import create_engine
from dotenv import load_dotenv

from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.linear_model import PoissonRegressor
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_absolute_error
from ml.shared_features import performance_features

load_dotenv()
DATABASE_URL = os.getenv("DATABASE_URL")
engine = create_engine(DATABASE_URL)
DATA_DIR = os.path.join(os.path.dirname(os.path.dirname(__file__)), "data")


def train_poisson():
    print("ğŸ“¥ NaÄÃ­tÃ¡m data pro Dixon-Coles (Poisson) model...")
    df = pd.read_sql("SELECT * FROM prepared_datasets", engine)

    # CÃ­lovÃ© promÄ›nnÃ©
    y_home = df["goals_home"]
    y_away = df["goals_away"]

    # Features
    try:
        df_fixt_cols = pd.read_sql("SELECT * FROM prepared_fixtures LIMIT 0", engine).columns
        valid_features = [f for f in performance_features if f in df.columns and f in df_fixt_cols]
    except:
        valid_features = [f for f in performance_features if f in df.columns]

    X = df[valid_features].replace([np.inf, -np.inf], np.nan)

    # Preprocessing
    imputer = SimpleImputer(strategy="mean")
    scaler = StandardScaler()

    X_imputed = imputer.fit_transform(X)
    X_scaled = scaler.fit_transform(X_imputed)

    print(f"ğŸš€ TrÃ©nuji regresory na {len(valid_features)} features...")

    # 1. TrÃ©nink zÃ¡kladnÃ­ch Poisson modelÅ¯
    reg_home = PoissonRegressor(alpha=0.5, max_iter=1000)
    reg_home.fit(X_scaled, y_home)

    reg_away = PoissonRegressor(alpha=0.5, max_iter=1000)
    reg_away.fit(X_scaled, y_away)

    # 2. VÃ½poÄet parametru RHO (Dixon-Coles Correction)
    # Rho mÄ›Å™Ã­ zÃ¡vislost mezi gÃ³ly domÃ¡cÃ­ch a hostÅ¯ (korelace reziduÃ­)
    pred_home = reg_home.predict(X_scaled)
    pred_away = reg_away.predict(X_scaled)

    # Rezidua (rozdÃ­l mezi realitou a predikcÃ­)
    res_home = y_home - pred_home
    res_away = y_away - pred_away

    # Kovariance reziduÃ­ / (std_h * std_a) -> Pearsonova korelace
    # ZjednoduÅ¡enÄ› pouÅ¾ijeme korelaci chyb
    rho = np.corrcoef(res_home, res_away)[0, 1]

    print(f"   ğŸ“ VypoÄÃ­tanÃ© Rho (zÃ¡vislost): {rho:.4f}")
    print("      (ZÃ¡pornÃ© Rho znamenÃ¡, Å¾e nÃ­zko skÃ³rujÃ­cÃ­ remÃ­zy jsou ÄastÄ›jÅ¡Ã­, neÅ¾ model ÄekÃ¡)")

    # Evaluace (MAE)
    tscv = TimeSeriesSplit(n_splits=5)
    mae_scores = []

    for train_idx, test_idx in tscv.split(X_scaled):
        X_test = X_scaled[test_idx]
        y_test_h = y_home.iloc[test_idx]
        y_test_a = y_away.iloc[test_idx]

        pred_h = reg_home.predict(X_test)
        pred_a = reg_away.predict(X_test)

        mae_h = mean_absolute_error(y_test_h, pred_h)
        mae_a = mean_absolute_error(y_test_a, pred_a)
        mae_scores.append((mae_h + mae_a) / 2)

    avg_mae = np.mean(mae_scores)
    print(f"   ğŸ“Š PrÅ¯mÄ›rnÃ¡ chyba (MAE): {avg_mae:.3f} gÃ³lÅ¯")

    # UloÅ¾enÃ­ - PÅ™idÃ¡vÃ¡me RHO do balÃ­Äku
    artifact = (imputer, scaler, reg_home, reg_away, valid_features, rho)
    joblib.dump(artifact, os.path.join(DATA_DIR, "model_poisson.pkl"))
    print("âœ… Dixon-Coles model (s Rho parametrem) uloÅ¾en.")


if __name__ == "__main__":
    train_poisson()