# ml/step3_1_train_model.py
# KOMPLETN√ç TR√âNINK: Feature Selection -> Voting Ensemble -> Poisson (Dixon-Coles)
# Tento skript nahrazuje step3 i step3b.

import os
import pandas as pd
import numpy as np
import joblib
from sqlalchemy import create_engine
from dotenv import load_dotenv

# Sklearn imports
from sklearn.model_selection import TimeSeriesSplit
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.metrics import accuracy_score, brier_score_loss, log_loss, f1_score, mean_absolute_error
from sklearn.feature_selection import RFECV
from sklearn.calibration import CalibratedClassifierCV
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.linear_model import LogisticRegression, PoissonRegressor
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier

# Naƒçten√≠ featur
from ml.shared_features import performance_features

load_dotenv()
DATABASE_URL = os.getenv("DATABASE_URL")
engine = create_engine(DATABASE_URL)
DATA_DIR = os.path.join(os.path.dirname(os.path.dirname(__file__)), "data")


def train_all_models():
    print("üöÄ START: Komplexn√≠ tr√©nink model≈Ø...")

    # --- 1. NAƒåTEN√ç DAT ---
    print("üì• Naƒç√≠t√°m data z DB...")
    df = pd.read_sql("SELECT * FROM prepared_datasets ORDER BY match_date ASC", engine)
    df = df.dropna(subset=["target"]).reset_index(drop=True)

    valid_features = [f for f in performance_features if f in df.columns]
    X_raw = df[valid_features].replace([np.inf, -np.inf], np.nan)

    # C√≠lov√© promƒõnn√©
    y_class = df["target"].astype(int)  # 0, 1, 2 (pro Klasifikaci)
    y_home = df["goals_home"]  # G√≥ly (pro Poisson)
    y_away = df["goals_away"]  # G√≥ly (pro Poisson)

    print(f"‚úÖ Data naƒçtena. {len(df)} z√°znam≈Ø, {len(valid_features)} features.")

    # --- 2. SELEKCE FEATURES (RFECV) ---
    # Vybereme features jednou a pou≈æijeme je pro OBA typy model≈Ø.
    # To zaruƒç√≠, ≈æe se nestane chyba "shape mismatch".
    tmp_imputer = SimpleImputer(strategy='mean')
    X_tmp = tmp_imputer.fit_transform(X_raw)

    print("üßπ Prov√°d√≠m selekci features (RFECV)...")
    selector = RFECV(
        estimator=RandomForestClassifier(n_jobs=-1, random_state=42, max_depth=5),
        step=1,
        cv=TimeSeriesSplit(3),
        scoring='neg_log_loss',
        min_features_to_select=10
    )
    selector.fit(X_tmp, y_class)

    selected_mask = selector.support_
    selected_features = [f for f, s in zip(valid_features, selected_mask) if s]

    print(f"   Vybr√°no: {len(selected_features)} features (z p≈Øvodn√≠ch {len(valid_features)}).")

    # P≈ô√≠prava fin√°ln√≠ch dat (Impute + Scale)
    X_selected = X_raw[selected_features]

    imputer = SimpleImputer(strategy='mean')
    scaler = StandardScaler()

    X_imp = imputer.fit_transform(X_selected)
    X_scaled = scaler.fit_transform(X_imp)

    tscv = TimeSeriesSplit(n_splits=3)

    # =========================================================================
    # ƒå√ÅST A: KLASIFIKACE (Voting Ensemble)
    # =========================================================================
    print("\nü§ñ ƒå√ÅST A: Tr√©nink klasifik√°tor≈Ø (1X2)...")

    models = {
        "logreg": LogisticRegression(solver='lbfgs', max_iter=1000, class_weight='balanced', C=0.1),
        "randomforest": RandomForestClassifier(n_estimators=150, max_depth=6, min_samples_leaf=4,
                                               class_weight='balanced', random_state=42),
        "gradientboost": GradientBoostingClassifier(n_estimators=100, learning_rate=0.05, max_depth=4, random_state=42),
        "svc": SVC(probability=True, kernel='rbf', C=0.5, class_weight='balanced', random_state=42),
        "knn": KNeighborsClassifier(n_neighbors=5, weights='distance'),
        "xgboost": XGBClassifier(eval_metric='mlogloss', n_estimators=100, max_depth=4, learning_rate=0.05,
                                 random_state=42)
    }

    trained_models = {}

    for name, clf in models.items():
        calibrated_clf = CalibratedClassifierCV(clf, method='isotonic', cv=tscv)

        # Rychl√Ω fit na cel√Ωch datech (validaci jsme u≈æ ladili)
        try:
            calibrated_clf.fit(X_scaled, y_class)
            trained_models[name] = calibrated_clf

            # Ulo≈æen√≠ jednotliv√Ωch model≈Ø
            joblib.dump((imputer, scaler, calibrated_clf, selected_features),
                        os.path.join(DATA_DIR, f"model_{name}.pkl"))
            print(f"   ‚úÖ {name}: Natr√©nov√°no a ulo≈æeno.")

        except Exception as e:
            print(f"   ‚ùå Chyba u {name}: {e}")

    # Voting Ensemble
    print("   üöÄ Skl√°d√°m Voting Ensemble...")
    voting_clf = VotingClassifier(
        estimators=[(name, model) for name, model in trained_models.items()],
        voting='soft'
    )
    voting_clf.fit(X_scaled, y_class)

    # Ulo≈æen√≠ Voting modelu
    joblib.dump((imputer, scaler, voting_clf, selected_features), os.path.join(DATA_DIR, "model_voting_ensemble.pkl"))
    print("üèÜ V√≠tƒõz: model_voting_ensemble.pkl ulo≈æen.")

    # =========================================================================
    # ƒå√ÅST B: REGRESE (Poisson / Dixon-Coles)
    # =========================================================================
    print("\n‚öΩ ƒå√ÅST B: Tr√©nink Poisson model≈Ø (G√≥ly)...")

    # Pou≈æijeme stejn√° ≈°k√°lovan√° data (X_scaled) - to zaruƒçuje kompatibilitu
    reg_home = PoissonRegressor(alpha=0.5, max_iter=1000)
    reg_home.fit(X_scaled, y_home)

    reg_away = PoissonRegressor(alpha=0.5, max_iter=1000)
    reg_away.fit(X_scaled, y_away)

    # V√Ωpoƒçet Rho (Dixon-Coles korelace)
    pred_h = reg_home.predict(X_scaled)
    pred_a = reg_away.predict(X_scaled)

    res_h = y_home - pred_h
    res_a = y_away - pred_a
    rho = np.corrcoef(res_h, res_a)[0, 1]

    print(f"   üìê Rho (korelace chyb): {rho:.4f}")

    # Ulo≈æen√≠ Poisson modelu
    # Form√°t: (imputer, scaler, reg_home, reg_away, selected_features, rho)
    joblib.dump((imputer, scaler, reg_home, reg_away, selected_features, rho),
                os.path.join(DATA_DIR, "model_poisson.pkl"))
    print("‚úÖ model_poisson.pkl ulo≈æen.")

    print("\nüèÅ HOTOVO. V≈°echny modely jsou synchronizovan√© a p≈ôipraven√©.")


if __name__ == "__main__":
    train_all_models()